{
  
    
        "post0": {
            "title": "Cats vs. Dogs",
            "content": ". 1. Introduction . Below shows the workings and investigations that have come about from doing the first lesson of the Fastai Deep Learning for Coders MOOC. As stated in my first blog post, this blog doesn&#39;t aim to impress, it&#39;s merely a documentation of a beginners journey into deep learning which may; or may not, help others in the future. . 2. Cats &amp; Dogs Vision Tutorial . 2.1 Vision Tutorial - from_name_func . I started the first Fastai Deep Learning for Coders lesson about a week before I actually ran the first box of code, error-free. This was due &#39;ImageDataLoaders&#39; not working which boiled down to my pillow package version not being compatible with other packages (I downgraded to pillow 8.2.0). Whilst I was losing hope with my pillow issues I came across the &#39;Tutorials&#39; section on the Fastai Docs site. I had been told about these in the past but forgot about them in my quest to get my AWS notebook instance working (link here on how I did this). Looking through the tutorials I decided that I would use them in conjunction with the lessons as they seemed pretty decent. In particular, I like the more incremental breakdown of the code. Therefore, I will start this first lesson with going through the Vision tutorial and playing around with a few things. . from fastai.vision.all import * path = untar_data(URLs.PETS) # Let&#39;s see what is inside this path print(&quot;Path:&quot;, path) print(&quot;Path contents:&quot;, path.ls()) . Path: /home/ec2-user/.fastai/data/oxford-iiit-pet Path contents: [Path(&#39;/home/ec2-user/.fastai/data/oxford-iiit-pet/images&#39;), Path(&#39;/home/ec2-user/.fastai/data/oxford-iiit-pet/annotations&#39;)] . I&#39;m only interested in the &#39;images&#39; folder for now. I&#39;ll use the get_image_files function to grab all of the image files (recursively) from the folder and put them in the &#39;files&#39; variable. . files = get_image_files(path/&#39;images&#39;) print(&quot;Number of objects in &#39;files&#39; variable:&quot;,len(files)) print(&quot;First file:&quot;,files[0]) print(&quot;Third file:&quot;,files[2]) . Number of objects in &#39;files&#39; variable: 7390 First file: /home/ec2-user/.fastai/data/oxford-iiit-pet/images/wheaten_terrier_96.jpg Third file: /home/ec2-user/.fastai/data/oxford-iiit-pet/images/Russian_Blue_160.jpg . There are 7,390 objects in the &#39;files&#39; variable. For the minute they are locations of files. In order to view the actual images we must use the PILimage.create function. . import matplotlib.pyplot as plt n = [0,1,2,3,4] r = 1 # Number of rows c = 5 # Number of columns s = 1 # Subplot counter fig = plt.figure(figsize=(15,15)) for i in n: plt.subplot(r,c,s) plt.imshow(PILImage.create(files[i])) plt.axis(&#39;off&#39;) s = s+1 . In order to build a supervised model from these images we need labels. The file names are labels, they state what bread the animal is in the image. The file names also state whether the image is of a dog or cat based on the first letter in the file name. If the first letter of the file name is a capital then that image is of a cat. Let&#39;s define a label function based on the first letter of the image name: . def label_func(f): return f[0].isupper() im = PILImage.create(files[0]) im.show(figsize=(4,4)) print(&quot;Below is an image of a cat, T/F?:&quot;,label_func(files[0].name)) . Below is an image of a cat, T/F?: False . In order to get the images ready for a model, they need to be put into a DataLoaders object. . dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224)) . The following is happening in the above section of code: . Telling the function the directory I&#39;m working in; | The files that I&#39;ve grabbed from that directory; | The function that defines the labels; and | Stated the transformation I want to apply (resize all images to 224x224 pixels). | Note that the function &#39;from_name_func&#39; is just an extention of the &#39;from_path_func&#39;. I&#39;ll show this later on. Also note that there are a number of additional arguments. From the documents: . ImageDataLoaders.from_name_func(path, fnames, label_func, valid_pct=0.2, seed=None, item_tfms=None, batch_tfms=None, bs=64, val_bs=None, shuffle=True, device=None) . The data is randomly split into training and validation sets based on the valid_pct input (with the option to seed the outcome). Any error or performance metrics will be calculated on the validation dataset. The validation data is a random subset of valid_pct based on val_bs which is the validation batch size. If val_bs isn&#39;t provided then bs is used by default. Similarly, the training data is a random subset based on bs which defaults to 64. . print(&quot;Training data batch size:&quot;, dls.train.bs) print(&quot;Validation data batch size:&quot;, dls.train.bs) print(&quot;Dependent variable unique level names:&quot;, dls.vocab) print(&quot;Dependent variable number of unique level names:&quot;, dls.c) . . Training data batch size: 64 Validation data batch size: 64 Dependent variable unique level names: [False, True] Dependent variable number of unique level names: 2 . dls.train.show_batch() . 2.2 Vision Tutorial - from_path_func . As I mentioned above, I could have used a different ImageDataLoaders function to create a DataLoaders object containing the pet images. Here we&#39;ll use the ImageDataLoader.from_path_func and define a new label function. . def label_func2(f): return f.name[0].isupper() im = PILImage.create(files[100]) im.show(figsize=(4,4)) print(&quot;Below is an image of a cat, T/F?:&quot;,label_func2(files[100])) . Below is an image of a cat, T/F?: True . dls2 = ImageDataLoaders.from_path_func(path, files, label_func2, item_tfms=Resize(224)) dls2.show_batch() . 2.3 Vision Tutorial - DataBlocks . Datablocks can be used to gather the data before it is passed to a dataloader. You can think of datablocks as a blue print or recipe that tells you how to assemble the data it will everytually be passed. This setup is a little less user friendly but I wanted to try get to grisps with it in case I want to use it in the future. . def label_func3(f): return &quot;cat&quot; if f.name[0].isupper() else &quot;dog&quot; im = PILImage.create(files[373]) im.show(figsize=(4,4)) print(&quot;Below is an image of a&quot;,label_func3(files[373])) . Below is an image of a dog . pets = DataBlock(blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, splitter=RandomSplitter(), get_y=label_func3, item_tfms=Resize(224)) . ImageBlock states what data type the independent variables are (images in this case). | CategoryBlock states what data type the dependent variable is (categorical variable in this case). | get_items provides the data (a folder of images file names in this case). | splitter defines how the validation set is created. | get_y defines the target variable that should be used (the label function) | item_tfms defines how each image is transformed (224 x 224 pixels). | . dls3 = pets.dataloaders(path/&quot;images&quot;) dls3.show_batch() . 3. Fastai Lesson One . 3.1 The first model . The first model is run roughly half way into the first lesson. Everything spoken about prior to that point is extremely useful and insightful but it is at this halfway point that I felt that I needed my AWS notebook instance up and running. Thus I&#39;m going to start from that stage in this script. . def is_cat(x): return x[0].isupper() dls = ImageDataLoaders.from_name_func(path, get_image_files(path), valid_pct=0.2, seed=42, label_func=is_cat, item_tfms=Resize(224)) learn = cnn_learner(dls, resnet34, metrics=error_rate) learn.fine_tune(3) . epoch train_loss valid_loss error_rate time 0 0.376693 0.240782 0.112991 01:05 epoch train_loss valid_loss error_rate time 0 0.246106 0.195579 0.078484 01:32 1 0.190142 0.171598 0.070027 01:33 2 0.144727 0.148527 0.058863 01:35 . Note: one epoch = one instance of the model looking through every image in the dataset once. . From the table above, I can see that as the model runs through more epochs the error rate (the proportion of images that were incorrectly identified) reduces. After running through the pets datasets 3 times, this model can tell the difference between an image of a dog and cat with great accuracy after less than 10 minutes run time (and very little knowledge!). This level of performance is not a given, resenet34 is a competition-winning model that has been pretrained on over a million images. Thus, fine-tuning this model on a new, more refined set of images (the act of which is called transfer learning) means I had a great starting point. . 3.2 Testing the model . I&#39;m going to test this model to see if it can correctly identify that my dog, Atlas, is in fact a dog (it is were a dog vs. cloud competition I may not be so optimistic). Here is the image of Atlas that I will use: . . from ipywidgets import FileUpload uploader = FileUpload() uploader . img = PILImage.create(uploader.data[0]) is_cat,_,probs = learn.predict(img) print(f&quot;Is this a cat?: {is_cat}.&quot;) print(f&quot;Probability it&#39;s a cat: {probs[1].item():.6f}&quot;) . Is this a cat?: False. Probability it&#39;s a cat: 0.000251 . Well, well, well. He&#39;s not a cat. And the model is pretty certain he isn&#39;t. I&#39;m impressed but at the same time scared by the vastness of what I don&#39;t know! . 4. Tips &amp; Tricks . Below is a list of smaller things I learnt over the course of lesson one that I found useful and dont want to forget. . Pressing &#39;H&#39; in command mode brings up a list of all functions available in command mode. | Using &#39;#&#39; in a code cell tells Python that what follows is a comment and so it should be ignored. | The kernel for this notebook is shown in the top right hand conrner under the &#39;Logout&#39; button. | An example of how to check a package&#39;s version and location is given below: | import PIL print(PIL.__version__) print(PIL.__file__) . The &#39;-qqq&#39; after an install command keeps a notebook clean. The &#39;q&#39; essentially stand for &#39;quiet&#39;. A single &#39;q&#39; will only show warnings and errors. Two &#39;q&#39;s only shows errors and three &#39;q&#39;s will disable all outputs. | I&#39;ve used quite a variety of code to show the images in this notebook. One I haven&#39;t used but want to remember is the following: | img = PILImage.create(files[1234]) img.to_thumb(192) .",
            "url": "https://mathschelsea.github.io/Blogging/jupyter/2021/07/28/lessonone.html",
            "relUrl": "/jupyter/2021/07/28/lessonone.html",
            "date": " • Jul 28, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "AWS NVIDIA GPU Instance Setup (for UK)",
            "content": ". 1. Prelimiary Points . 1.1 Why do I need an NVIDIA GPU? . I&#39;m completeing the Deep Learning for Coders with fastai &amp; PyTorch course by Jeremy Howard and Sylvain Gugger which; by the way, is amazing and very alturistic of them (thanks both!). To actually do the course I need access to a GPU. Now, I&#39;m in no way an expert on software engineering but through reading the course book it says that the tasks handled by a GPU are very similar to those done by a neural network. Therefore, for this course, computing over a GPU is superior to that of a CPU. In addition, not any old GPU will be supported by the main deep learning libraries therefore I need access to an NVIDIA GPU. . 1.2 Why am I using AWS? . I&#39;ve decided to complete this course using Amazon Sagemaker notebook instances. The reason for this is because I already use AWS at work but mainly as a cloud storage platform (s3 buckets). I&#39;d like to see what other wizardry it houses. . 1.3 Alternative Guides . There are a couple of guides on how to get set-up with Amazon Sagemaker as well as other servers such as Paperspace Gradient and Google Colab. However, I&#39;ve found that some of the steps are different for people living in the UK so I thought I&#39;d create this slightly alternative guide. I&#39;m also very new to remote server usage and deep learing so I thought I&#39;d create a more incremental guide for the absolute beginners among us (I feel your pain). . 2. AWS Account &amp; Service Quota Increase . 2.1 AWS Account . In order to use Amazon Sagemarker you need an AWS account. This is really simple to set-up, just follow Amazon&#39;s instructions in this post here. Note, you&#39;ll need your credit or debit card details to hand. . 2.2 Service Quota Increase . When you create an AWS account you&#39;ll be assigned the default quotas (also referred to as &#39;limits&#39;) for a variety of services (images, instances etc.) based on your region (I&#39;m based in the UK so my region is eu-west-2). These defaults might work for you or you may want to go up a notch with them. As I said at the start, for the Fastai course I need a specific GPU and so I need to request a &#39;limit increase&#39;. . Now as I&#39;ve said, I&#39;m no software engineer and I had a bit of a hard time following the quides at this point. According to the steps, I needed to request a &#39;ml.p2.xlarge&#39; instance however this isn&#39;t currently available in my region. I then went in search of the next best thing and found this wonderful article which helped me decide on requesting a &#39;g4dn.xlarge&#39; instance. . Note, the request can take a day or two for AWS support to process. So make sure you account for this if you&#39;re trying to stick to a schedule or deadline. . 2.3 Steps for request . 1 - On the AWS console home page find the &#39;Support&#39; drop down located in the top right hand corner and select &#39;Support Center&#39; from the list. . . 2 - On the support center home page select &#39;Create Case&#39;. . . 3 - Then select &#39;Service Limit Increase&#39;. This will populate the lower part of the page. . . 4 - In &#39;Limit type&#39; select &#39;SageMaker Notebook Instances&#39;. . . 5 - Select the region (I chose &#39;EU (London)&#39;) and the Limit (I selected &#39;ml.g4dn.xlarge&#39;). . . 6 - Add a case description (I said I was completed thing Fastai course and needed an NVIDIA GPU at an affordable price). . 7 - Press &#39;Submit&#39;. . 8 - A new case will be opened in the &#39;Support Center&#39; and an AWS support will be in touch with you. . 3. CloudFormation . 3.1 CloudFormation . Once your service quota increase has been approved it&#39;s time to create a CloudFormation stack. I think of these stacks as your blueprint. It&#39;s a set of resources that you define and freeze at a point in time. It means that you can replicate a certain situation or environment again and again. Frequently when using Python or Conda packages there will be an update to one package which is incompatbile with another. This can result in a script being fine one day but failing the next day after a package update. It&#39;s really annoying. Having an environment that is frozen in time means that your code can run without fail well into the future. I&#39;m sure the advantage of using stacks isn&#39;t limited to just this but it&#39;s what stood out to me. . 3.2 Stack Templates . A series of stack templates are provided on the Fastai site however; as I&#39;ve stated before, these are set-up with an instance type of &#39;ml.p2.xlarge&#39; which isn&#39;t available in the EU London (eu-west-2) region. Therefore, what I did was download the YAML file and edit it so that the instance choices include &#39;ml.g4dn.xlarge. I then saved this new YAML file to an S3 bucket of my own and created a stack based on that. . 3.3 Stack Setup . 1 - Download the Fastai EU London template using this link. . 2 - Edit the default instance type to be &#39;ml.g4dn.xlarge&#39; (line 4 below) and also add it as an allowed values (line 8). I did this edit in Visual Studio Code for ease and saved the edits over the original YAML file. . . 3 - Steps 3 to 6 guide you through uploading your YAML file to an S3 bucket so that your CloudFormation stack can access it as a stack template. This isn&#39;t necessary therefore if you&#39;re not interested in S3 buckets or knowing this bit then skip to step 7. Next thing to do is to upload this edited YAML file to an S3 bucket. To do this, return to your AWS management console page and in the search bar type &#39;S3&#39; and select &#39;S3&#39; from the drop down list. . . 4 - In order to upload the YAML file to an S3 bucket, you need to create one. Just click the &#39;Create Bucket&#39; button, give your bucket a name (I called mine &#39;ct-fastai-coursev4&#39;) and scrole down to &#39;Create Bucket&#39;. You should see your S3 bucket in the list like mine below: . . 5 - Now, click on this new bucket and upload your YAML file. You&#39;ll do this by selecting &#39;Upload&#39; and doing some drag and drop action with your YAML file. Once done your file should appear in the bucket. . . 6 - Click on your YAML file that you&#39;ve just uploaded and copy the objects URL. You&#39;ll need this when creating your CloudFoundation stack. . 7 - Time to go back to the AWS management console page and in the search bar type &#39;CloudFormation&#39; and select &#39;CloudFormation&#39; from the drop down list. . . 8 - Click the &#39;Create Stack&#39; button. On the form select &#39;Template is ready&#39;. If you&#39;re coming straight from step 3 then you should select your template source as &#39;Upload a template&#39; and chose your edited YAML file from step 2. If you&#39;ve gone through steps 3 to 6 then you can select your template source as &#39;Amazon S3 URL&#39; and paste in the object URL from step 6. . . 9 - Enter a stack name (I called it FastaiSageMakerStack) , the instance type as &#39;ml.g4dn.xlarge&#39; and volume size as &#39;50&#39; and click &#39;Next&#39;. I then clicked &#39;Next&#39; for the following page without changing anything and created the stack. The below page should then appear which shows the stack being created. . . 10 - Wait for the stack&#39;s status to change to &#39;CREATE_COMPLETE&#39; before moving on. . . 4. Sagemaker Instance . 4.1 Notebook Setup . 1 - Go to the AWS Management Console page and type &#39;Sagemarker&#39; in the search bar. Select &#39;Amazon SageMaker&#39;. . . 2 - On the right hand panel select &#39;Notebook&#39; and then &#39;Notebook Instances&#39;. A page should appear with your notebook instances, in the list should be the notebook &#39;fastai-v4&#39; that was created from our CloudFormation stack (line 196 of the YAML file). . . 3 - Right click on the &#39;Open in Jupyter&#39; option and select &#39;Open in new tab&#39;. This should open the Jupyter web interface and all of the material for the Fastai course. . . 4 - When you open your first notebook, you&#39;ll be asked to select a kernel. Make sure to choose the &#39;fastai&#39; kernel. If that isn&#39;t an option, give it 20 minutes as your instance will need a bit of time to setup the first time it is opened. If it still doesn&#39;t appear as a kernel option then you might need to use the following YAML file that a very kind person on that forums has created (I had to do this and then repeat step 2 in the 3.3 &#39;Stack Setup&#39; section): . https://forums.fast.ai/t/sagemaker-notebook-deployment-problem-no-fastai-kernel/88806/10?u=chelsea . . 4.2 Important . Important! Always stop your notebook instance when you are done. If you don&#39;t stop your notebook instance from running, you will continue to be charged. Always make sure to stop all of your notebook instances before you sign out of your AWS account. . .",
            "url": "https://mathschelsea.github.io/Blogging/jupyter/2021/07/12/setup.html",
            "relUrl": "/jupyter/2021/07/12/setup.html",
            "date": " • Jul 12, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "And so it begins...",
            "content": "Mission Statement . &quot;I will not rest until I have you holding a Coke, wearing your own shoe, playing a Sega game featuring you, while singing your own song in a new commercial, starring you, broadcast during the Superbowl, in a game that you are winning, and I will not sleep until that happens&quot; - Jerry Maguire . These writings don&#39;t aim to impress. They are simply an account of one person&#39;s learning curve. The intention is to showcase an honest journey that is accessible to all. Too often topics like Data Science are shrouded in mystery, kept from the masses by large organisations and the highest levels of education. When learnings are shared, they usually alienate eager pupils with overly-complicated content. This suffocation of aspiration needs to end and a new wave of alternative learning needs to emerge. It&#39;s time to be kind and share our journey - the good and the bad. It&#39;s also time to be gracious and remember that all teachers were once pupils. Here is my account. . Who is Chelsea Tucker? . A lover of all things technical, I spend my day as a Data Scientist building machine learning models that; in a nutshell, predict the future. Pretty neat. By evening I champion and promote women in STEM subjects through speaking at events and creating content on Instagram, YouTube and TikTok. I aim to ignite a belief in young people that they have what it takes to thrive in a world of numbers and computing; regardless of gender or race. I also acknowledge that not everyone is dealt the same privileges in life and so I create free visually appealing mathematical learning materials using my background in both fine art and mathematics. And I do all of this with copious amounts of Yorkshire tea and intermittent holidays that revolve around longboarding, kitesurfing and general &quot;vanlife&quot; antics. . .",
            "url": "https://mathschelsea.github.io/Blogging/jupyter/2021/07/02/begin.html",
            "relUrl": "/jupyter/2021/07/02/begin.html",
            "date": " • Jul 2, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About",
          "content": ". Chelsea Tucker . A lover of all things technical, I spend my day as a Data Scientist building machine learning models that; in a nutshell, predict the future. Pretty neat. By evening I champion and promote women in STEM subjects through speaking at events and creating content on Instagram, YouTube and TikTok. I aim to ignite a belief in young people that they have what it takes to thrive in a world of numbers and computing; regardless of gender or race. I also acknowledge that not everyone is dealt the same privileges in life and so I create free visually appealing mathematical learning materials using my background in both fine art and mathematics. And I do all of this drinking copious amounts of Yorkshire tea, buying aesthetically pleasing stationary and planning holidays that revolve around longboarding, kitesurfing and general “vanlife” antics. . Blog Mission Statement - Jerry Maguire style . These writings don’t aim to impress. They are simply an account of one person’s learning curve. The intention is to showcase an honest journey that is accessible to all. Too often topics like Data Science are shrouded in mystery, kept from the masses by large organisations and the highest levels of education. When learnings are shared, they usually alienate eager pupils with overly-complicated content. This suffocation of aspiration needs to end and a new wave of alternative learning needs to emerge. It’s time to be kind and share our journey - the good and the bad. It’s also time to be gracious and remember that all teachers were once pupils. . MathsChelsea . The intention behind the ‘MathChelsea’ Instagram and Youtube account was to create a platform of freely accessible mathematical learning materials that rebel against the notion that maths is difficult, mundane and irrelevant. The result is a collection of worksheets and videos that teach technical topics through bursts of colour and unconventional contexts. In addition to learning materials, these socials also house illustrations that champion female figures in STEM who come from underprivileged or minority backgrounds. . . Bits and Bobs . Education: . MMath Mathematics at The University of Leeds | Msc Exploration Geophysics at The University of Leeds | . STEM: . Stemettes 2021 #EasterExplore Speaker | YFYA 2020 Speaker | Stemettes 2020 #Outbox2020 Speaker | Women in Mathematics Article | Tips for Maths Careers Article | .",
          "url": "https://mathschelsea.github.io/Blogging/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://mathschelsea.github.io/Blogging/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}